\section{Implementation Details}
\label{sec:Implementation Details}
This section focuses on an elaborate description of the implementation details of distributed graph traversal algorithms. Also, it describes certain assumptions and challenges faced during the implementation phase.

\subsection{Assumptions}
Before diving deep into the implementation details, it is necessary to describe certain assumptions we have considered to make the graph traversal algorithm distributed in nature.
First of all, the clustering methodology is incorporated to divide the data into partitions with the nearest nodes. Each node in our dataset consists of the real-world location taken from the geographical dataset mentioned in the previous section. We have considered the data-parallel approach with master-slave architecture for designing our distributed algorithm. Each slave is assigned with a cluster of nodes along with the graph consists of connectivity between them. Once a source and destination point is supplied, the master node will find out the cluster to which the source and destination points belong to. In some instances, the source and destination can belong to the same cluster, which is our best-case scenario. In this case, instead of traversing the entire graph, the shortest path algorithm is run in that particular cluster with full computation power, which will lead to less time than traversing the entire graph.  However, if the source and destination do not belong to the same cluster, the master node detects the clusters with source and destination node and sends them to the corresponding nodes for computation.

Secondly, clustering is done during the data processing phase, which is before starting the actual graph traversal. We assumed that the number of clusters is equal to the number of slave nodes. Hence, we can easily assign each cluster to a slave for shortest path computation.

Finally, both partitioned based and hierarchical clustering is used for generating the distributed data partitions. K-means is used as a representative of partitioned based clustering whereas Agglomerative clustering is used for the hierarchical one. It is expected that an excellent clustering method will detect a neighborhood with the smallest distances between each pair of locations.

\subsection{Implementation Details}
Our entire methodology can be divided into two steps. The first part is to divide the entire graph network into clusters of neighbors, and the second part is to parallelize the shortest path algorithm.

Python is used as the default language for our implementation, and mainly the functionality provided by the NetworkX package is used for different graph-related algorithmic implementations. The data import pipeline is implemented using APIs provided by NetworkX and OSMNX. First, we converted the Open Street Map data into a graphical representation using OSMNx, and then it is supplied to the NetworkX to generate a NetworkX graph. After the graph is generated, we run clustering techniques over that graph to divide the data and stored it in their respective nodes as a pickle object. Each graph object will consist of some nodes which provide a gateway to other nodes. We select the nodes in each cluster that have an edge connecting to the other cluster and defined them as gateway nodes. After the gateway nodes are detected, we also store that information into a pickle for further processing.

Although we can divide the data into different clusters, we need to find the path among clusters. This path will primarily consist of all the gateways. We first find out which gateways inside a node are connected to each other. If there is a path between two nodes, we join then with a single edge to represent the existence of an intra-cluster gateway path. So, we finally have all the gateway nodes and their connection information, which we used to construct a gateway to gateway graph and store that information in the master node for further processing.

In the second phase, we tried to parallelize the shortest path algorithm using data-parallel approach. After the designated cluster is located with the information provided by source and destination, we divided our tasks into mainly 4 kinds of subtasks as follows:

\begin{itemize}
	\item Determine the shortest path from source to the gateway nodes of the respective cluster
	\item Determine the shortest path from destination to destination for the respective cluster.
	\item Find out the gateway to gateway shortest paths inside each cluster other than source and destination
	\item find the shortest path between inter-cluster gateways
\end{itemize}

The master node determines the respective cluster for source and destination, and it sends the source and destination node to their respective clusters. The source cluster tries to find out the shortest paths from the source node to the gateways. Also, the destination node tries to find the shortest path from the gateway to the destination in the destination cluster in parallel. Other nodes also try to find the shortest gateway to gateway paths in their cluster. The master node loads the graph of gateways from the pickle and tries to find out the inter-cluster shortest path using gateways. After all these four parallel processes completed, the respected results are sent to the master node. Finally, the master node uses the provided information and tries to find out the shortest path between source and destination by merging the paths provided in previous steps. MPI is used for running the tasks in parallel and also for the exchange of necessary pieces of information between master and slaves. Our implementation also has the provision to designate one node to run as both master and slave in parallel.

\subsection{Challenges}
We have faced several challenges during our implementation phase, both in terms of accuracy and latency of our algorithm. The primary challenge was to prepare an inter-gateway graph creation, which will give us necessary information about the existence of inter-cluster shortest paths. We tried to keep the graph as simple as possible by only keeping the gateway nodes in this graph and replacing the entire path between them with a single edge if there is any path between two gateway nodes. However, the most complicated part of our implementation was to merge the information provided by each cluster and use the gateway graph information to determine the shortest path from source to cluster. In the initial step, we tried to call the single source shortest path algorithm multiple times to find out the shortest path from source gateway to the destination gateway, which increases the latency of our algorithm significantly. However, we solve that issue by using a multi-source shortest path for each destination, and it improves the overall performance of our implementation. Further, we face some challenges to join the source and gateway paths as we can get multiple shortest paths for each of the gateway nodes. We keep them in sorted order by distance and use that notion while doing the merging at master.

So overall, our algorithm tries to find out the shortest path between the source and the gateway nodes, the shortest path between inter-gateway nodes, and also the shortest path between gateway nodes and destination. Finally, it merges the paths with the shortest distances, which give a complete shortest path from source to destination.